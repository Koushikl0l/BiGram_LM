{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6faaf545-d120-4f1d-ba7d-de5720b18d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3882429d-0f0d-4526-ba8b-c49750d0dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 32\n",
    "block_size = 8\n",
    "max_iters = 3000\n",
    "eval_interval = 200\n",
    "learning_rate = 1e-3\n",
    "eval_iters = 200\n",
    "# ------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1270c566-e429-47f5-8d1a-bcbd0965d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# !wget https://github.com/Koushikl0l/BiGram_LM/blob/main/input.txt\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34716c09-3b97-440b-991e-0adb9989618d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original String: hello\n",
      "Encoded List: [46, 43, 50, 50, 53]\n",
      "Decoded String: hello\n"
     ]
    }
   ],
   "source": [
    "#find out number of character in shakespeare\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "# Convert character to numeric\n",
    "char_to_index = {char: index for index, char in enumerate(chars)}\n",
    "# Retrieve numeric and convert to character\n",
    "index_to_char = {index: char for index, char in enumerate(chars)}\n",
    "# Encode a string to numeric values\n",
    "def encode(s):\n",
    "    return [char_to_index[c] for c in s]\n",
    "# Decode a list of numeric values to a string\n",
    "def decode(l):\n",
    "    return ''.join([index_to_char[i] for i in l])\n",
    "\n",
    "# Example usage\n",
    "example_string = \"hello\"\n",
    "encoded_example = encode(example_string)\n",
    "decoded_example = decode(encoded_example)\n",
    "\n",
    "print(f\"Original String: {example_string}\")\n",
    "print(f\"Encoded List: {encoded_example}\")\n",
    "print(f\"Decoded String: {decoded_example}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1ef3d07-c5f4-4712-b293-5a4afd08b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(encode(text), dtype=np.int32)\n",
    "#split data in train/val\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f93e6961-f7e9-46bd-9a7c-57291fa6b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data_split = train_data if split == 'train' else val_data\n",
    "    ix = np.random.randint(len(data_split) - block_size, size=(batch_size,))\n",
    "    x = np.stack([data_split[i:i + block_size] for i in ix])\n",
    "    y = np.stack([data_split[i + 1:i + block_size + 1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8165b04-cdaa-450a-b2d1-465fa2659158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.trainable = False\n",
    "    for split in ['train', 'val']:\n",
    "        losses = np.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss\n",
    "        out[split] = losses.mean()\n",
    "    model.trainable = True\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c4d45bd-994e-413d-880f-2b8f1417b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(BigramLanguageModel, self).__init__()\n",
    "        self.token_embedding_table = Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def call(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape #(samples, sequence_length, embedding_dimensionality)\n",
    "            logits = tf.reshape(logits, (B * T, C))\n",
    "            targets = tf.reshape(targets, (B * T,))\n",
    "            #here the operations: column-wise operatoins\n",
    "            loss = SparseCategoricalCrossentropy(from_logits=True)(targets, logits)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, _ = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = tf.nn.softmax(logits, axis=-1)\n",
    "            idx_next = tf.random.categorical(tf.math.log(probs), num_samples=1)\n",
    "            idx = np.concatenate((idx, idx_next.numpy()), axis=1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e0af891-0422-49d2-9bb8-6a91694e9a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 200: train loss 4.1787, val loss 4.1780\n",
      "step 400: train loss 3.9696, val loss 3.9698\n",
      "step 600: train loss 3.7789, val loss 3.7831\n",
      "step 800: train loss 3.6082, val loss 3.6095\n",
      "step 1000: train loss 3.4554, val loss 3.4584\n",
      "step 1200: train loss 3.3207, val loss 3.3253\n",
      "step 1400: train loss 3.1999, val loss 3.2059\n",
      "step 1600: train loss 3.0956, val loss 3.1002\n",
      "step 1800: train loss 3.0054, val loss 3.0148\n",
      "step 2000: train loss 2.9256, val loss 2.9339\n",
      "step 2200: train loss 2.8585, val loss 2.8608\n",
      "step 2400: train loss 2.8056, val loss 2.8141\n",
      "step 2600: train loss 2.7648, val loss 2.7660\n",
      "step 2800: train loss 2.7192, val loss 2.7204\n",
      "step 3000: train loss 2.6793, val loss 2.6910\n",
      "step 3200: train loss 2.6498, val loss 2.6616\n",
      "step 3400: train loss 2.6235, val loss 2.6297\n",
      "step 3600: train loss 2.6037, val loss 2.6155\n",
      "step 3800: train loss 2.5867, val loss 2.5974\n",
      "step 4000: train loss 2.5724, val loss 2.5831\n",
      "step 4200: train loss 2.5608, val loss 2.5669\n",
      "step 4400: train loss 2.5397, val loss 2.5580\n"
     ]
    }
   ],
   "source": [
    "model = BigramLanguageModel(vocab_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "for iter in range(4400):\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter+eval_interval}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        xb, yb = get_batch('train')\n",
    "        logits, loss = model(xb, yb)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ded9614a-d747-49cd-b2bb-12ba27858243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "$; into3;WeKnelveS:\n",
      "ut or; h l hapary blorst l d;CURI's w! ? UMape ber phothewe ha d --ns.\n",
      "Themy dest crMGLUn th Rur:\n",
      "\n",
      "So certhe!\n",
      "Gl wPuMBGoveachil hepp\n",
      "TCA:\n",
      "WIjuspeve e. JurwoMonom\n",
      "LK!Wy tounchrvblld shZNI plUKnd otThidiSUthe or mes k, Hed ffout?ven,Z?\n",
      "AMHind lare be heenoubgarichaf, ky it kenclferathorxbrovefine. frertyon:\n",
      "Whort lliou ar.\n",
      "WAf thinsou:STEre'seros, OUNURK:\n",
      "A\n",
      "\n",
      "Bee my &rrtpprearid a liubeathe avecke tills atrdlNGe intetomp t.\n",
      "GI if m'I,frwoxoire f VusART:US:\n",
      "Whichothe?\n",
      "Athkn sy.Y\n"
     ]
    }
   ],
   "source": [
    "context = np.zeros((1, 1), dtype=np.int32)\n",
    "generated_sequence = model.generate(context, max_new_tokens=500)[0].tolist()\n",
    "print(decode(generated_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fbbe2c51-bbe0-4f49-969b-fb28e025d90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56088500-df73-4461-a6c1-b9acf3d46f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6cb0b0b9-751b-4f97-8d88-4d0e81d67686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.93205695, 0.58655181, 0.42026529, 0.10302102, 0.85046747],\n",
       "        [0.4562592 , 0.56113383, 0.31352333, 0.52387294, 0.78175231],\n",
       "        [0.71225975, 0.98892264, 0.49564897, 0.52969973, 0.05272602]],\n",
       "\n",
       "       [[0.38938281, 0.92210432, 0.3504762 , 0.76611183, 0.97759941],\n",
       "        [0.12684861, 0.33399306, 0.47437419, 0.23737499, 0.01243637],\n",
       "        [0.46860414, 0.53661618, 0.62543445, 0.8272151 , 0.25304255]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61d1ae3e-7273-4a7f-9b05-103679da9b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93205695, 0.58655181, 0.42026529, 0.10302102, 0.85046747],\n",
       "       [0.4562592 , 0.56113383, 0.31352333, 0.52387294, 0.78175231],\n",
       "       [0.71225975, 0.98892264, 0.49564897, 0.52969973, 0.05272602],\n",
       "       [0.38938281, 0.92210432, 0.3504762 , 0.76611183, 0.97759941],\n",
       "       [0.12684861, 0.33399306, 0.47437419, 0.23737499, 0.01243637],\n",
       "       [0.46860414, 0.53661618, 0.62543445, 0.8272151 , 0.25304255]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.reshape((2*3),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1a95b7-3e1a-43ea-a6f5-10921dde6948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
